\documentclass[conference]{IEEEtran}
\usepackage{cite}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{listings}
\usepackage[hyphens]{url}
\usepackage[hidelinks,pdfusetitle]{hyperref}
\usepackage{xcolor}
\usepackage{siunitx}

\hypersetup{
    breaklinks=true,
    pdfauthor={Diogo Medeiros}
}
\urlstyle{same}

\newcommand{\BibTeX}{{\textrm{B} \kern-.05em{\textsc{i} \kern-.025em b}\kern-.08em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\lstdefinestyle{mystyle}{
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}

\begin{document}

    \title{Icon Generation with Conditional Generative Adversarial Networks}

    \author{\IEEEauthorblockN{Diogo Medeiros}
    \IEEEauthorblockA{\textit{School of Science and Technology} \\
    \textit{University of Tr√°s-os-Montes and Alto Douro}\\
    Vila Real, Portugal \\
    al70633@alunos.utad.pt}
    }
    \maketitle

    \begin{abstract}
        Conditional Generative Adversarial Networks (cGANs) were used to generate icons with specific characteristics or properties given the Icons-50 dataset.
        The performance of the cGANs was impacted by the imbalanced nature of the original dataset.
        Filtering the original dataset to include only the 10 most frequent classes (the Icons-10 dataset) improved the performance of the cGANs, allowing them to generate more detailed and striking icons.
        This paper demonstrates the potential of cGANs for use in applications where a large number of icons with specific characteristics are needed.
    \end{abstract}

    \begin{IEEEkeywords}
        GAN, cGAN, Icons-50, icons, style, applications
    \end{IEEEkeywords}


    \section{Introduction}\label{sec:introduction}
    \input{sections/introduction}

    \section{Materials and Methods}\label{sec:materials-and-methods}
    \input{sections/materials-and-methods}


    \section{Results}\label{sec:results}
    \input{sections/results}


    \section{Discussion}\label{sec:discussion}

    When dealing with imbalanced data, such as the Icons-50 dataset, it is important to consider how this may impact the training of a machine learning (ML) model, especially when the number of classes is large.

    When trained with the original unfiltered data, the discriminator was able to achieve a high accuracy of around 96\% and a small loss of 0.329.
    While these results would be optimal in their own, when analyzed alongside the generator's performance, the model seemed to overfit the data, possibly due to the large number of classes, finishing off with a disappointing loss of 2.532.

    Afterwards, I decided to filter out the dataset by choosing the 10 most frequent classes, in the hope that when training a new model, I would be able to achieve better results when it came to the icon generation.
    I called this new dataset, fittingly, the Icons-10 dataset.

    I then trained a new model with an identical structure to the first one, but now on the filtered data.
    As to be expected, while the discriminator suffered a slight dip in performance, with an accuracy of 85\% and a loss of 1.433, the generator improved quite significantly, with a lower loss of 1.433.

    When analyzing the icons generated by each model, it became apparent that, while the first model was able to learn the overall structure and element composition of the icon, particularly in the case of the ``family'' class, the results were lackluster and lacked the proper detail to discern what they represented, without the added context, as seen in Fig.~\ref{fig:Icons50Clock},\ref{fig:Icons50Family}.

    This suggests that the generator may not have been deep or large enough to learn the necessary features for generating icons for 50 different classes, while the model trained with the Icons-10 dataset was able to learn and generated detailed and striking images, such as Fig.~\ref{fig:Icons10Clock},\ref{fig:Icons10Family}.


    \section{Conclusions}\label{sec:conclusions}
    In this paper, the ability of conditional generative adversarial networks (cGANs) to generate icons with specific characteristics or properties was explored using the Icons-50 dataset.
    To address the issue of imbalanced data in the original unfiltered dataset, a new dataset was created by filtering the original dataset to include only the 10 most frequent classes (the Icons-10 dataset).

    When comparing the performance of the cGANs trained on these two datasets, it was found that the model trained on the Icons-10 dataset was able to generate more detailed and striking icons compared to the model trained on the unfiltered data.
    This suggests that the model trained on the Icons-10 dataset was able to learn more effectively and generate more accurate and representative icons for the desired classes.

    In conclusion, cGANs can be an effective tool for generating icons with specific characteristics or properties, given a suitable dataset.
    In this case, filtering the original dataset to include only the most frequent classes improved the performance of the cGANs, demonstrating the importance of considering the impact of imbalanced data on model training.

    Future work could include testing the performance of cGANs with different hyper-parameters or architectures, or using a different dataset with more balanced class distribution.
    Additionally, exploring the use of cGANs for generating icons with other specific characteristics or properties, such as color or shape, could be a valuable direction for future research.

    \bibliographystyle{IEEEtran}
    \bibliography{references}

\end{document}
